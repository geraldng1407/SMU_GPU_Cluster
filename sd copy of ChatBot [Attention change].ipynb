{"cells":[{"cell_type":"markdown","metadata":{"id":"HoQ4_TlXybJ9"},"source":["###Importing Libraries"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3110,"status":"ok","timestamp":1699268956381,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"FomGQannBHye","outputId":"ccbb1206-cb20-41b1-bd0f-9a28a648b459"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5508,"status":"ok","timestamp":1699280871434,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"mVkBeAG-dTPF"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import unicodedata\n","import re"]},{"cell_type":"markdown","metadata":{"id":"6-iJx8HwyhLr"},"source":["###Reading the Data"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699268960169,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"AGVOl6J-Bszb","outputId":"fdedfc2b-1052-440b-ba54-af59c1a3f14a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CS425/Chatbot_Project\n"]}],"source":["%cd drive/MyDrive/CS425/Chatbot_Project"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1699268960781,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"RsJ7lLK1Cay_"},"outputs":[],"source":["file = open('./data/output_truncate_20.txt','r').read()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":822,"status":"ok","timestamp":1699268962103,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"sSNomuT7Jsvv"},"outputs":[],"source":["raw_data = [f.split('\\t') for f in file.split('\\n')]    #separating questions and answers\n","questions = [x[0] for x in raw_data]\n","answers = [x[1] if len(x) > 1 else \"\" for x in raw_data]"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699268962103,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"oiA-0GwtJwYd","outputId":"066524b0-eb12-4b54-855e-00be5c115df9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Question:  What is the relationship between very low Mg2+ levels, PTH levels, and Ca2+ levels?\n","Answer:  Very low Mg2+ levels correspond to low PTH levels which in turn results in low Ca2+ levels.\n"]}],"source":["print(\"Question: \", questions[0])\n","print(\"Answer: \", answers[0])"]},{"cell_type":"markdown","metadata":{"id":"HFuAVvFuyo64"},"source":["###Tokenizing"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699268963869,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"WXM48uqPI24W"},"outputs":[],"source":["def tokenize(lang):\n","    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n","    lang_tokenizer.fit_on_texts(lang)\n","    tensor = lang_tokenizer.texts_to_sequences(lang)\n","    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n","    return tensor, lang_tokenizer"]},{"cell_type":"markdown","metadata":{"id":"P57M5HwNyrtM"},"source":["###PreProcessing"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1925,"status":"ok","timestamp":1699268966820,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"qtQWA702Iwxx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"500959f1-655a-47d3-c911-491e76e8b2c4"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["def preprocess_sentence(sentence):\n","    sentence = ''.join(c for c in unicodedata.normalize('NFD', sentence) if unicodedata.category(c) != 'Mn')\n","    sentence = sentence.lower().strip()\n","    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n","    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n","    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n","    sentence = '<start> ' + sentence + ' <end>'\n","    return sentence"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":6574,"status":"ok","timestamp":1699268973393,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"ubN0jC6zJ0hH"},"outputs":[],"source":["pre_questions = [preprocess_sentence(w) for w in questions] #processing all the quesstions\n","pre_answers = [preprocess_sentence(w) for w in answers] #processing all the answers"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1699268973393,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"EsOXfre3KSDy"},"outputs":[],"source":["data = pre_answers, pre_questions"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699268973394,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"ryMnanp0KBWw"},"outputs":[],"source":["def prepare_data(data):\n","    targ_lang, inp_lang = data\n","\n","    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n","    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n","\n","    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":829,"status":"ok","timestamp":1699268988008,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"xJV_dqtyKYzm"},"outputs":[],"source":["input_tensor, target_tensor, inp_lang, targ_lang = prepare_data(data)\n","\n","# Calculate max_length of the target tensors\n","max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":308,"status":"ok","timestamp":1699268989971,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"uQAe2JYuJycK","outputId":"8bc6c186-3d41-4cd4-8099-a6b79cf20fe1"},"outputs":[{"output_type":"stream","name":"stdout","text":["28\n","24\n"]}],"source":["print(max_length_targ)\n","print(max_length_inp)"]},{"cell_type":"markdown","metadata":{"id":"n7uEiPyo7DyI"},"source":["### Downloading the Tokenizers"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":430,"status":"ok","timestamp":1699268993013,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"Fjor8_8K6__v"},"outputs":[],"source":["import pickle\n","\n","def save_tokenizer(tokenizer, filename):\n","    with open(filename, 'wb') as handle:\n","        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","save_tokenizer(inp_lang, 'input_tokenizer.pkl')\n","save_tokenizer(targ_lang, 'target_tokenizer.pkl')"]},{"cell_type":"markdown","metadata":{"id":"TqptaUlQyw5m"},"source":["###Splitting the Data"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":459,"status":"ok","timestamp":1699268995047,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"bXEJ-kkDWDIH","outputId":"2cb8763e-5dd0-4587-c232-5609edaeca4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train size: 11906\n","Test size: 1488\n","Validation size: 1489\n"]}],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","# Split the data into 80% train, 10% test, 10% val\n","input_tensor_train, input_tensor_test_val, target_tensor_train, target_tensor_test_val = train_test_split(\n","    input_tensor, target_tensor, test_size=0.2, random_state=42)\n","\n","input_tensor_test, input_tensor_val, target_tensor_test, target_tensor_val = train_test_split(\n","    input_tensor_test_val, target_tensor_test_val, test_size=0.5, random_state=42)\n","\n","print(f'Train size: {len(input_tensor_train)}')\n","print(f'Test size: {len(input_tensor_test)}')\n","print(f'Validation size: {len(input_tensor_val)}')\n"]},{"cell_type":"markdown","metadata":{"id":"H3nQQ917yzKF"},"source":["###Defining the PipeLine"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":558,"status":"ok","timestamp":1699268997548,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"GUeolMd9SKHY","outputId":"1b337a39-632e-44d6-809f-ba04236466d0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([128, 24]), TensorShape([128, 28]))"]},"metadata":{},"execution_count":22}],"source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 128\n","steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n","embedding_dim = 200\n","units = 750\n","vocab_inp_size = len(inp_lang.word_index)+1\n","vocab_tar_size = len(targ_lang.word_index)+1\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n","\n","example_input_batch, example_target_batch = next(iter(dataset))\n","example_input_batch.shape, example_target_batch.shape\n"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699268999190,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"Nk-cafrc3WM8"},"outputs":[],"source":["class Encoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","        super(Encoder, self).__init__()\n","        self.batch_sz = batch_sz\n","        self.enc_units = enc_units\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.lstm = tf.keras.layers.LSTM(self.enc_units,\n","                                         return_sequences=True,\n","                                         return_state=True,\n","                                         recurrent_initializer='glorot_uniform')\n","        self.dropout = tf.keras.layers.Dropout(0.2)\n","\n","    def call(self, x, hidden):\n","      x = self.embedding(x)\n","      x = self.dropout(x)  # Apply dropout to the input\n","      output, state_h, state_c = self.lstm(x, initial_state=hidden)  # Use LSTM with state_h and state_c\n","      state = [state_h, state_c]\n","      return output, state\n","\n","    def initialize_hidden_state(self):\n","        return [tf.zeros((self.batch_sz, self.enc_units)),\n","                tf.zeros((self.batch_sz, self.enc_units))]\n","\n","encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":463,"status":"ok","timestamp":1699269001990,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"adO6-QxYKlwx"},"outputs":[],"source":["import tensorflow as tf\n","\n","class Attention(tf.keras.layers.Layer):\n","    def __init__(self, units, use_scaling=True, use_masking=False, dropout_rate=0.1):\n","        super(Attention, self).__init__()\n","        self.W1 = tf.keras.layers.Dense(units)\n","        self.W2 = tf.keras.layers.Dense(units)\n","        self.V = tf.keras.layers.Dense(1)\n","        self.use_scaling = use_scaling\n","        self.use_masking = use_masking\n","        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","    def call(self, query, values, mask=None):\n","        query_with_time_axis = tf.expand_dims(query, 1)\n","        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n","\n","        if self.use_scaling:\n","            score = score / tf.math.sqrt(tf.cast(tf.shape(query_with_time_axis)[-1], tf.float32))\n","\n","        if self.use_masking and mask is not None:\n","            score += (1 - mask) * -1e9  # Apply masking to scores\n","\n","        attention_weights = tf.nn.softmax(score, axis=1)\n","        attention_weights = self.dropout(attention_weights)\n","\n","        context_vector = attention_weights * values\n","        context_vector = tf.reduce_sum(context_vector, axis=1)\n","        context_vector = self.layer_norm(context_vector)\n","\n","        return context_vector, attention_weights"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":352,"status":"ok","timestamp":1699269017828,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"ucM7JAxI4vM3"},"outputs":[],"source":["class Decoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","        super(Decoder, self).__init__()\n","        self.batch_sz = batch_sz\n","        self.dec_units = dec_units\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.lstm = tf.keras.layers.LSTM(self.dec_units,\n","                                         return_sequences=True,\n","                                         return_state=True,\n","                                         recurrent_initializer='glorot_uniform')\n","        self.fc = tf.keras.layers.Dense(vocab_size)\n","        self.attention = Attention(self.dec_units)\n","\n","    def call(self, x, hidden, enc_output):\n","        context_vector, attention_weights = self.attention(hidden[0], enc_output)\n","\n","        x = self.embedding(x)\n","\n","        # Concatenate context vector and embedding\n","        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","        # Passing the concatenated vector to the LSTM\n","        output, state_h, state_c = self.lstm(x, initial_state=hidden)  # Use LSTM with state_h and state_c\n","\n","        state = [state_h, state_c]\n","\n","        output = tf.reshape(output, (-1, output.shape[2]))\n","        x = self.fc(output)\n","\n","        return x, state, attention_weights\n","\n","decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"4uHuaQpny3Wk"},"source":["###Adjusting Learning Rates"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":400,"status":"ok","timestamp":1699269021368,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"Z0Z62qj-ZLru"},"outputs":[],"source":["initial_learning_rate = 0.001 #adaptive learning rate\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate, decay_steps=1000, decay_rate=0.9, staircase=True\n",")\n","\n","# Define the optimizer with adaptive learning rate\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n","\n","# Define your loss function\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none'\n",")\n","\n","def loss_function(real, pred):  #defining loss function\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    loss_ = loss_object(real, pred)\n","\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","\n","    return tf.reduce_mean(loss_)\n"]},{"cell_type":"markdown","metadata":{"id":"oXFR4CAxy9Od"},"source":["###Defining Train Step"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":308,"status":"ok","timestamp":1699269023666,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"ftqY-Rj_XNlW"},"outputs":[],"source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","    loss = 0\n","\n","    with tf.GradientTape() as tape:\n","        enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","        # Initialize LSTM's initial state\n","        dec_hidden = [enc_hidden[0][:, :units], enc_hidden[1][:, :units]]\n","\n","        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n","\n","        # Teacher forcing - feeding the target as the next input\n","        for t in range(1, targ.shape[1]):\n","            # Passing enc_output to the decoder\n","            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","            loss += loss_function(targ[:, t], predictions)\n","\n","            # Using teacher forcing\n","            dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","    batch_loss = (loss / int(targ.shape[1]))\n","\n","    variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","    gradients = tape.gradient(loss, variables)\n","\n","    optimizer.apply_gradients(zip(gradients, variables))\n","\n","    return batch_loss"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":479,"status":"ok","timestamp":1699269026830,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"lo-wQ2NPXOKm"},"outputs":[],"source":["@tf.function\n","def validation_step(inp, targ, enc_hidden):\n","    val_loss = 0\n","\n","    val_samples = 0\n","\n","    enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","    # Initialize LSTM's initial state\n","    dec_hidden = [enc_hidden[0][:, :units], enc_hidden[1][:, :units]]\n","\n","    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n","\n","    for t in range(1, targ.shape[1]):\n","        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","        loss = loss_function(targ[:, t], predictions)\n","        val_loss += loss\n","        val_samples += 1\n","        dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","    val_loss /= val_samples\n","\n","    return val_loss"]},{"cell_type":"markdown","metadata":{"id":"FWKFyJ9ey__t"},"source":["###Training the Pipeline"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"fEBjc3KTdgE-","executionInfo":{"status":"error","timestamp":1699270367478,"user_tz":-480,"elapsed":1309312,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"}},"outputId":"dcec315a-4ffc-40d0-bc10-7c12e86d6e56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch:  1 Loss:2.8500 Val Loss:2.7992\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-501360eb2e9e>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Implement early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Early stopping triggered.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_best_weights\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_weights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m             \u001b[0;31m# Restore the weights after first epoch if no progress is ever made.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_weights'"]}],"source":["import matplotlib.pyplot as plt\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","\n","# Define early stopping\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","# Define the optimizer with gradient clipping\n","optimizer = Adam(learning_rate=lr_schedule, clipvalue=1.0)  # Added gradient clipping\n","\n","EPOCHS = 15\n","\n","train_losses = []\n","val_losses = []\n","for epoch in range(1, EPOCHS + 1):\n","    enc_hidden = encoder.initialize_hidden_state()\n","    total_loss = 0\n","\n","    # Training loop\n","    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","        batch_loss = train_step(inp, targ, enc_hidden)\n","        total_loss += batch_loss\n","\n","    num_samples = 0\n","    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","        enc_output, enc_hidden = encoder(inp, enc_hidden)\n","        dec_hidden = enc_hidden\n","        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n","\n","        for t in range(1, targ.shape[1]):\n","            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","            predicted_id = tf.argmax(predictions, axis=-1)\n","            num_samples += 1\n","            dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","    validation_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n","    validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=True)\n","\n","    val_loss = 0\n","    val_samples = 0\n","\n","    for (batch, (inp, targ)) in enumerate(validation_dataset):\n","        enc_hidden = encoder.initialize_hidden_state()  # Initialize hidden state for each batch\n","        val_batch_loss = validation_step(inp, targ, enc_hidden)\n","        val_loss += val_batch_loss\n","        val_samples += 1\n","\n","    val_loss /= val_samples\n","\n","    if epoch % 1 == 0:\n","        train_losses.append(total_loss / steps_per_epoch)\n","        val_losses.append(val_loss)\n","        print('Epoch:{:3d} Loss:{:.4f} Val Loss:{:.4f}'.format(\n","            epoch, total_loss / steps_per_epoch,  val_loss))\n","\n","    # Implement early stopping\n","    if early_stopping.on_epoch_end(epoch, logs={'val_loss': val_loss}):\n","        print(\"Early stopping triggered.\")\n","        break\n","\n","# Plotting the accuracy and loss graphs\n","plt.figure(figsize=(12, 6))\n","\n","# Plot training and validation losses\n","plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train')\n","plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8632,"status":"ok","timestamp":1699243114060,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"8c2YfFId3U5Y","outputId":"f315a0e6-4230-41a5-d4f3-4feaad97186e"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:<__main__.Attention object at 0x7dabae3c7ca0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]}],"source":["encoder.save(\"encoder_dropOutwithNormalization\")\n","decoder.save(\"decoder_dropOutwithNormalization\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1954,"status":"ok","timestamp":1699243157329,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"12f5dE5E3XZ-","outputId":"196770cb-3d6d-49e8-b078-5fc669c113a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: encoder_dropOutwithNormalization/ (stored 0%)\n","  adding: encoder_dropOutwithNormalization/variables/ (stored 0%)\n","  adding: encoder_dropOutwithNormalization/variables/variables.data-00000-of-00001 (deflated 7%)\n","  adding: encoder_dropOutwithNormalization/variables/variables.index (deflated 39%)\n","  adding: encoder_dropOutwithNormalization/assets/ (stored 0%)\n","  adding: encoder_dropOutwithNormalization/saved_model.pb (deflated 90%)\n","  adding: encoder_dropOutwithNormalization/fingerprint.pb (stored 0%)\n","  adding: encoder_dropOutwithNormalization/keras_metadata.pb (deflated 81%)\n"]}],"source":["!zip -r \"encoder_dropOutwithNormalization.zip\" \"encoder_dropOutwithNormalization\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5775,"status":"ok","timestamp":1699243165325,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"14lbjgIC3acq","outputId":"70a4284d-6f85-4eaf-8771-c380145be42c"},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: decoder_dropOutwithNormalization/ (stored 0%)\n","  adding: decoder_dropOutwithNormalization/variables/ (stored 0%)\n","  adding: decoder_dropOutwithNormalization/variables/variables.data-00000-of-00001 (deflated 7%)\n","  adding: decoder_dropOutwithNormalization/variables/variables.index (deflated 54%)\n","  adding: decoder_dropOutwithNormalization/assets/ (stored 0%)\n","  adding: decoder_dropOutwithNormalization/saved_model.pb (deflated 90%)\n","  adding: decoder_dropOutwithNormalization/fingerprint.pb (stored 0%)\n","  adding: decoder_dropOutwithNormalization/keras_metadata.pb (deflated 86%)\n"]}],"source":["!zip -r \"decoder_dropOutwithNormalization.zip\" \"decoder_dropOutwithNormalization\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFtSqTElXltk"},"outputs":[],"source":["def remove_tags(sentence):\n","    return sentence.split(\"<start>\")[-1].split(\"<end>\")[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w3qbBcT6IPkf"},"outputs":[],"source":["def evaluate(sentence):\n","    sentence = preprocess_sentence(sentence)\n","\n","    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n","    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                         maxlen=max_length_inp,\n","                                                         padding='post')\n","    inputs = tf.convert_to_tensor(inputs)\n","\n","    result = ''\n","\n","    hidden = [tf.zeros((1, units)), tf.zeros((1, units))]\n","    enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","    dec_hidden = enc_hidden\n","    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n","\n","    for t in range(max_length_targ):\n","        predictions, dec_hidden, attention_weights = decoder(dec_input,\n","                                                             dec_hidden,\n","                                                             enc_out)\n","        attention_weights = tf.reshape(attention_weights, (-1, ))\n","\n","        predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","        result += targ_lang.index_word[predicted_id] + ' '\n","\n","        if targ_lang.index_word[predicted_id] == '<end>':\n","            return remove_tags(result), remove_tags(sentence)\n","\n","        # the predicted ID is fed back into the model\n","        dec_input = tf.expand_dims([predicted_id], 0)\n","\n","    return remove_tags(result), remove_tags(sentence)\n"]},{"cell_type":"markdown","metadata":{"id":"1hET8yaDBBk7"},"source":["### Testing some random questions"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":331},"executionInfo":{"elapsed":34,"status":"error","timestamp":1699280814967,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"RG40LpHdONCG","outputId":"52b6dfe2-89fe-4ed0-baac-270263d217cf"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a438af185cad>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted answer:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Relationship between very low Mg2+ levels, PTH levels, and Ca2+ levels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-1-a438af185cad>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0manswer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Question:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted answer:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"]}],"source":["def test(question):\n","    answer, question = evaluate(question)\n","    print('Question:', question)\n","    print('Predicted answer:', answer)\n","\n","test(\"Relationship between very low Mg2+ levels, PTH levels, and Ca2+ levels\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699243400224,"user":{"displayName":"LEE SHAO DONG _","userId":"12272995022260015063"},"user_tz":-480},"id":"DyVK67Qpyhd6","outputId":"85905700-6e65-48d3-dffc-c94ec9f374f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  what is the most severe form of thalassemia and what are the typical symptoms associated with it \n","Predicted answer: the most common cause of seizure in adults is thalassemia . \n"]}],"source":["test(\"What is the most severe form of β-thalassemia and what are the typical symptoms associated with it\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"99zBE0TPZ8WG","outputId":"dd68980d-b4e5-4fb1-8a8d-87f303e5c5e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  hello \n","Predicted answer: greetings ! \n","Question:  how are you doing ? \n","Predicted answer: fine , and you ? \n","Question:  what is your age ? \n","Predicted answer: i am still young by your standards . \n","Question:  do you have a tv ? \n","Predicted answer: yes , i do . \n","Question:  do you like rain ? \n","Predicted answer: yes , i love traveling and exploring new places . \n"]}],"source":["test(\"Hello\")\n","test(\"How are you doing?\")\n","test(\"What is your age?\")\n","test(\"Do you have a tv?\")\n","test(\"Do you like rain?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvz7kNlj25-K","outputId":"4e32399c-d419-40c7-a278-e350139045c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  i am afraid \n","Predicted answer: why ? do i frighten you ? try not to be too scared . what are you afraid of ? \n"]}],"source":["test(\"I am afraid\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yJoKOlrM28e9","outputId":"f4a5539c-0924-4be7-fc7c-d12c3d10a299"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  i am feeling sick \n","Predicted answer: oh , really ? \n"]}],"source":["test(\"I am feeling sick\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bCDxO6fiNyjr","outputId":"3c971737-1215-4dba-c5d0-e6648372b41d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  sorry \n","Predicted answer: yeah , so do i . \n"]}],"source":["test(\"Sorry\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11vTxcJRN0AS","outputId":"453c65bd-87c2-4325-9acf-667197149c2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  hi , how are you doing ? \n","Predicted answer: i m fine . how about yourself ? \n"]}],"source":["test(\"hi, how are you doing?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YGgZlEWfN5sG","outputId":"77507157-5750-48eb-da97-0969e0489d3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  i m pretty good . thanks for asking . \n","Predicted answer: no problem . so how have you been ? \n"]}],"source":["test(\"i'm pretty good. thanks for asking.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"61qs3yLVN8Ko","outputId":"7cd07063-8f05-4f72-8f38-36118072cf43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  i ve been great . what about you ? \n","Predicted answer: i ve been good . i m in school right now . \n"]}],"source":["test(\"i've been great. what about you?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rTylB062N_qd","outputId":"687e05c3-e014-4ef9-f0c3-ce1f642470f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  what school do you go to ? \n","Predicted answer: i go to pcc . \n"]}],"source":["test(\"what school do you go to?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZ3xo_rNOEwB","outputId":"5321db08-bfce-4614-8398-80a4908cc254"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  i don t know \n","Predicted answer: i like the ones i can sing along with . \n"]}],"source":["test(\"I don't know\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mvaXsRBMOGk9","outputId":"810c7d02-4152-4603-9900-6b3cf4504e2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  nice to meet you \n","Predicted answer: thank you . \n"]}],"source":["test(\"nice to meet you\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XOrbnn6zOJvj","outputId":"8ce3c076-7169-4fc8-99e8-0d046f0bf41f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  what are your hobbies ? \n","Predicted answer: i enjoy reading books and playing the guitar . \n"]}],"source":["test(\"What are your hobbies?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"le5qUCLbOMAF","outputId":"eaf250ac-7a94-44df-f01f-f38fd8ccba0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  you are rude \n","Predicted answer: yep . i always behave in socially unacceptable ways . \n"]}],"source":["test(\"You are rude\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKqioan4ONn6","outputId":"bf2f7666-1e59-4d20-d7e0-3f52b7642441"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question:  i love you \n","Predicted answer: i love you , too . \n"]}],"source":["test(\"I love you\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eB1yEq__OTEw"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1qhqCisZ3seiVOxY4AeebMQlnDLM-RsYa","timestamp":1699201829385}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}